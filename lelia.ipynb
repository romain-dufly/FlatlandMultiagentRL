{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map-related methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Base flatland environment\n",
    "from flatland.envs.line_generators import SparseLineGen\n",
    "from flatland.envs.malfunction_generators import (\n",
    "    MalfunctionParameters,\n",
    "    ParamMalfunctionGen,\n",
    ")\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_generators import SparseRailGen\n",
    "from flatland.envs.observations import GlobalObsForRailEnv\n",
    "\n",
    "from flatland.envs.observations import TreeObsForRailEnv\n",
    "from flatland.envs.distance_map import DistanceMap\n",
    "import flatland.envs.rail_env_shortest_paths as sp\n",
    "\n",
    "from src import test_utils, training, rewards\n",
    "from src.observation_utils import normalize_observation\n",
    "from src.models import *\n",
    "from src.deep_model_policy import DeepPolicy, PolicyParameters\n",
    "\n",
    "# Visualization\n",
    "from flatland.utils.rendertools import RenderTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "\n",
    "env = RailEnv(\n",
    "    width=20,\n",
    "    height=15,\n",
    "    rail_generator=SparseRailGen(\n",
    "        max_num_cities=2,  # Number of cities\n",
    "        grid_mode=True,\n",
    "        max_rails_between_cities=2,\n",
    "        max_rail_pairs_in_city=1,\n",
    "    ),\n",
    "    line_generator=SparseLineGen(speed_ratio_map={1.: 1.}\n",
    "        ),\n",
    "    number_of_agents=2, \n",
    "    obs_builder_object=TreeObsForRailEnv(max_depth=3),\n",
    "    malfunction_generator=ParamMalfunctionGen(\n",
    "        MalfunctionParameters(\n",
    "            malfunction_rate=0.,  # Rate of malfunction\n",
    "            min_duration=3,  # Minimal duration\n",
    "            max_duration=20,  # Max duration\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "_,_ = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning from bitmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A \"rail occupancy bitmap\" shows on which rail and in which direction the agent is traveling at every timestep and is obtained. A directed graph representation of the railway network is generated through BFS, each node is a switch and each edge is a rail between two switches.\n",
    "2. The shortest path for each agent is computed\n",
    "3. The path is transformed into a bitmap with the timesteps as columns and the rails as rows. The direction is 1 if the agent is traveling the edge from the source node to the destination node or -1 otherwise.\n",
    "\n",
    "The general architecture is a Dueling DQN, where the input is a Conv2D layer that processes a concatenation of the agent bitmap, the positive and the negative heatmaps. Then data goes through two separate streams, the value and the advantage to be recombined in the final output Q values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "Dueling DQN model\n",
    "'''\n",
    "def dim_output(input_dim, filter_dim, stride_dim):\n",
    "    return (input_dim - filter_dim) // stride_dim + 1\n",
    "\n",
    "class Dueling_DQN(nn.Module):\n",
    "    def __init__(self, width, height, action_space):\n",
    "        super(Dueling_DQN, self).__init__()\n",
    "        self.action_space = action_space\n",
    "        # input shape (batch_size, in_channels = height/num_rails, width/prediction_depth + 1) \n",
    "        # self.conv1 = nn.Conv1d(in_channels=height, out_channels=64, kernel_size=1)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(1, width))\n",
    "\n",
    "        # output shape (batch_size, out_channels, conv_width)\n",
    "        # conv_width = dim_output(input_dim=width, filter_dim=20, stride_dim=1)\n",
    "\n",
    "        # in_features = conv_width * out_channels (feature maps/number of kernels, arbitrary)\n",
    "        # after last Conv1d\n",
    "        self.fc1_adv = nn.Linear(in_features=64 * height, out_features=512) \n",
    "        self.fc1_val = nn.Linear(in_features=64 * height, out_features=512)\n",
    "        self.fc2_adv = nn.Linear(in_features=512, out_features=action_space)\n",
    "        self.fc2_val = nn.Linear(in_features=512, out_features=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): # \n",
    "        # batch_size = x.size(0)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        adv = self.relu(self.fc1_adv(x))\n",
    "        val = self.relu(self.fc1_val(x))\n",
    "\n",
    "        adv = self.fc2_adv(adv)\n",
    "        val = self.fc2_val(val).expand(x.size(0), self.action_space)\n",
    "\n",
    "        x = val + adv - adv.mean(1).unsqueeze(1).expand(x.size(0), self.action_space)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "class ObsPreprocessor:\n",
    "    def __init__(self, max_rails, reorder_rails):\n",
    "        self.max_rails = max_rails\n",
    "        self.reorder_rails = reorder_rails\n",
    "\n",
    "    def _fill_padding(self, obs, max_rails):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param obs: Agent state \n",
    "        :param max_rails: Maximum number of rails in environment \n",
    "        :return: Observation padded with 0s along first axis (until max_rails)\n",
    "        \n",
    "        \"\"\"\n",
    "        prediction_depth = obs.shape[1]\n",
    "        \n",
    "        pad_agent_obs = np.zeros((max_rails, prediction_depth))\n",
    "        pad_agent_obs[:obs.shape[0], :obs.shape[1]] = obs\n",
    "        \n",
    "        return pad_agent_obs\n",
    "\n",
    "    # (agents x rails x depth)\n",
    "    def _get_heatmap(self, handle, bitmaps, max_rails):\n",
    "        temp_bitmaps = np.copy(bitmaps)\n",
    "        temp_bitmaps[handle, :, :] = 0\n",
    "        pos_dir = np.sum(np.where(temp_bitmaps > 0, temp_bitmaps, 0), axis=0)\n",
    "        neg_dir = np.abs(np.sum(np.where(temp_bitmaps < 0, temp_bitmaps, 0), axis=0))\n",
    "        \n",
    "        return pos_dir, neg_dir\n",
    "\n",
    "    def _swap_rails(self, bitmap, swap):\n",
    "        bitmap[range(len(swap))] = bitmap[swap]\n",
    "        bitmap[len(swap):, :] = 0\n",
    "        return bitmap\n",
    "\n",
    "\n",
    "    def _reorder_rails(self, bitmap, pos_map, neg_map):\n",
    "        swap = np.array([], dtype=int)\n",
    "\n",
    "        ts = 0 \n",
    "        rail = np.argmax(np.absolute(bitmap[:, ts]))\n",
    "        # If agent not departed\n",
    "        if bitmap[rail, ts] == 0:\n",
    "            ts = 1\n",
    "            rail = np.argmax(np.absolute(bitmap[:, ts]))\n",
    "        \n",
    "        # While the bitmap is not empty\n",
    "        while bitmap[rail, ts] != 0:\n",
    "            swap = np.append(swap, rail)\n",
    "            ts += np.argmax(bitmap[rail, ts:] == 0)\n",
    "            rail = np.argmax(np.absolute(bitmap[:, ts]))\n",
    "\n",
    "        if len(swap) > 0:\n",
    "            bitmap = self._swap_rails(bitmap, swap)\n",
    "            pos_map = self._swap_rails(pos_map, swap)\n",
    "            neg_map = self._swap_rails(neg_map, swap)\n",
    "        \n",
    "        return bitmap, pos_map, neg_map\n",
    "\n",
    "    def get_obs(self, handle, bitmap, maps):\n",
    "        # Select subset of conflicting paths in bitmap\n",
    "        pos_map, neg_map = self._get_heatmap(handle, maps, self.max_rails)\n",
    "\n",
    "        if self.reorder_rails:\n",
    "            bitmap, pos_map, neg_map = self._reorder_rails(bitmap, pos_map, neg_map)\n",
    "\n",
    "        state = np.concatenate([\n",
    "            self._fill_padding(bitmap, self.max_rails),\n",
    "            self._fill_padding(pos_map, self.max_rails),\n",
    "            self._fill_padding(neg_map, self.max_rails)\n",
    "        ])\n",
    "        \n",
    "        return state # (prediction_depth + 1, max_cas * max_rails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import Optional, List, Dict, Tuple, NamedTuple\n",
    "\n",
    "Waypoint = NamedTuple(\n",
    "    'Waypoint', [('position', Tuple[int, int]), ('direction', int)])\n",
    "\n",
    "CardinalNode = \\\n",
    "\tNamedTuple('CardinalNode', [('id_node', int), ('cardinal_point', int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we implement a class that returns the rails occupancy as a bitmap with rails on y-axis and timesteps on x-axis. Rails are edges and the 1/-1 in the bitmap indicate the direction of the agent on the rail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n        --- timesteps --->\\nrail 0: 1 1 1       -1-1\\nrail 1:      1 1\\nrail 2:         -1-1\\n.\\n.\\nrail n:\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "        --- timesteps --->\n",
    "rail 0: 1 1 1       -1-1\n",
    "rail 1:      1 1\n",
    "rail 2:         -1-1\n",
    ".\n",
    ".\n",
    "rail n:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:379: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:382: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:379: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:382: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "C:\\Users\\lelia\\AppData\\Local\\Temp\\ipykernel_26508\\1420684031.py:379: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(holes == 0, \"All the cells of the bitmap should be filled\")\n",
      "C:\\Users\\lelia\\AppData\\Local\\Temp\\ipykernel_26508\\1420684031.py:382: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(np.all(temp), \"Thee agent's bitmap shouldn't have holes \")\n"
     ]
    }
   ],
   "source": [
    "from flatland.core.env import Environment\n",
    "from flatland.core.env_observation_builder import ObservationBuilder\n",
    "from flatland.core.grid.grid4_utils import get_new_position, direction_to_point\n",
    "from flatland.envs.rail_env import RailEnvActions\n",
    "from flatland.envs.step_utils.states import TrainState\n",
    "\n",
    "class RailObsForRailEnv(ObservationBuilder):\n",
    "\n",
    "\tdef __init__(self, predictor):\n",
    "\t\t\"\"\"\n",
    "\t\tpredictor: class that predicts the path.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(RailObsForRailEnv, self).__init__()\n",
    "\t\tself.predictor = predictor\n",
    "\t\t\n",
    "\t\tself.num_agents = None\n",
    "\t\tself.num_rails = None # Depends on the map, must be computed in reset()\n",
    "\t\tself.max_time_steps = self.predictor.max_depth\n",
    "\n",
    "\t\t# Not all of them are necessary\n",
    "\t\tself.cell_to_id_node = {} # Map cell position : id_node\n",
    "\t\tself.id_node_to_cell = {} # Map id_node to cell position\n",
    "\t\tself.info = {} # Map id_edge : tuple (CardinalNode1, CardinalNode2, edge_length)\n",
    "\t\tself.id_edge_to_cells = {} # Map id_edge : list of tuples (cell pos, crossing dir) in rail (nodes are not counted)\n",
    "\t\tself.nodes = set() # Set of node ids\n",
    "\t\tself.edges = set() # Set of edge ids\n",
    "\n",
    "\t\tself.recompute_bitmap = True\n",
    "\n",
    "\tdef set_env(self, env: Environment):\n",
    "\t\tsuper().set_env(env)\n",
    "\t\tif self.predictor:\n",
    "\t\t\t# Use set_env available in PredictionBuilder (parent class)\n",
    "\t\t\tself.predictor.set_env(self.env)\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.cell_to_id_node = {}\n",
    "\t\tself.id_node_to_cell = {}\n",
    "\t\tself.info = {}\n",
    "\t\tself.id_edge_to_cells = {}\n",
    "\t\tself.nodes = set()\n",
    "\t\tself.edges = set()\n",
    "\t\tself._map_to_graph()\n",
    "\t\tself.recompute_bitmap = True\n",
    "\n",
    "\t\tself.num_agents = len(self.env.agents)\n",
    "\n",
    "\t\t# Calculate agents timesteps per cell\n",
    "\t\tself.tpc = dict()\n",
    "\t\tfor a in range(self.num_agents):\n",
    "\t\t\tagent_speed = self.env.agents[a].speed_data['speed']\n",
    "\t\t\tself.tpc[a] = int(np.reciprocal(agent_speed))\n",
    "\t\t\n",
    "\tdef get_many(self, handles: Optional[List[int]] = None):\n",
    "\t\tmaps = None\n",
    "\t\t# Compute bitmaps from shortest paths\n",
    "\t\tif self.recompute_bitmap:\n",
    "\t\t\tself.recompute_bitmap = False\n",
    "\n",
    "\t\t\tprediction_dict = self.predictor.get()\n",
    "\t\t\tself.paths = self.predictor.shortest_paths\n",
    "\t\t\tcells_sequence = self.predictor.compute_cells_sequence(prediction_dict)\n",
    "\n",
    "\t\t\tmaps = np.zeros((self.num_agents, self.num_rails, self.max_time_steps + 1), dtype=int)\n",
    "\t\t\tfor a in range(self.num_agents):\n",
    "\t\t\t\tmaps[a, :, :] = self._bitmap_from_cells_seq(a, cells_sequence[a])\n",
    "\n",
    "\t\t\tmaps = np.roll(maps, 1)\n",
    "\t\t\tmaps[:, :, 0] = 0\n",
    "\n",
    "\t\treturn maps\n",
    "\n",
    "\tdef get_altmaps(self, handle):\n",
    "\t\tagent = self.env.agents[handle]\n",
    "\t\taltpaths, cells_seqs = self.predictor.get_altpaths(handle, self.cell_to_id_node)\n",
    "\t\tmaps = []\n",
    "\t\tfor i in range(len(cells_seqs)):\n",
    "\t\t\tbitmap = self._bitmap_from_cells_seq(handle, cells_seqs[i])\n",
    "\n",
    "\t\t\t# If agent not departed, add 0 at the beginning\n",
    "\t\t\tif agent.status == TrainState.READY_TO_DEPART:\n",
    "\t\t\t\tbitmap[:, -1] = 0\n",
    "\t\t\t\tbitmap = np.roll(bitmap, 1)\n",
    "\n",
    "\t\t\tmaps.append(bitmap)\n",
    "\n",
    "\t\treturn maps, altpaths\n",
    "\n",
    "\tdef get_agent_action(self, handle):\n",
    "\t\tagent = self.env.agents[handle]\n",
    "\t\taction = RailEnvActions.DO_NOTHING\n",
    "\t\t\n",
    "\t\tif agent.status == TrainState.READY_TO_DEPART:\n",
    "\t\t\taction = RailEnvActions.MOVE_FORWARD\n",
    "\n",
    "\t\telif agent.status == TrainState.MOVING:\n",
    "\t\t\t# This can return None when rails are disconnected or there was an error in the DistanceMap\n",
    "\t\t\tif self.paths[handle] is None or len(self.paths[handle]) == 0:  # Railway disrupted\n",
    "\t\t\t\tprint('[WARN] AGENT {} RAIL DISRUPTED'.format(handle))\n",
    "\t\t\t\taction = RailEnvActions.STOP_MOVING\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Get action\n",
    "\t\t\t\tstep = self.paths[handle][0]\n",
    "\t\t\t\tnext_action_element = step.next_action_element.action  # Get next_action_element\n",
    "\n",
    "\t\t\t\t# Just to use the correct form/name\n",
    "\t\t\t\tif next_action_element == 1:\n",
    "\t\t\t\t\taction = RailEnvActions.MOVE_LEFT\n",
    "\t\t\t\telif next_action_element == 2:\n",
    "\t\t\t\t\taction = RailEnvActions.MOVE_FORWARD\n",
    "\t\t\t\telif next_action_element == 3:\n",
    "\t\t\t\t\taction = RailEnvActions.MOVE_RIGHT\n",
    "\t\t\t\t\n",
    "\t\t\t\tself.paths[handle] = self.paths[handle][1:]\n",
    "\n",
    "\t\treturn action\n",
    "\n",
    "\tdef is_before_switch(self, a):\n",
    "\t\tagent = self.env.agents[a]\n",
    "\t\tbefore_switch = False\n",
    "\n",
    "\t\tif agent.state == TrainState.MOVING :\n",
    "\t\t\tif len(self.paths[a]) > 0:\n",
    "\t\t\t\tcurr_pos = agent.position\n",
    "\t\t\t\tnext_pos = self.paths[a][0].next_action_element.next_position\n",
    "\t\t\t\tcurr_rail, _ = self._get_edge_from_cell(curr_pos)\n",
    "\t\t\t\tnext_rail, _ = self._get_edge_from_cell(next_pos)\n",
    "\t\t\t\tbefore_switch = curr_rail != -1 and next_rail == -1\n",
    "\t\t\telse:\n",
    "\t\t\t\t# This shouldn't happen, but it may happen\n",
    "\t\t\t\tprint('[WARN] agent\\'s {} path run out'.format(a))\n",
    "\t\t\t\t# Force path recalc\n",
    "\t\t\t\tbefore_switch = True\n",
    "\n",
    "\t\treturn before_switch\n",
    "\n",
    "\tdef _get_rail_dir(self, a, maps, ts=0):\n",
    "\t\trail = np.argmax(np.absolute(maps[a, :, ts]))\n",
    "\t\tdirection = maps[a, rail, ts]\n",
    "\t\treturn rail, direction\n",
    "\n",
    "\t# This should only be used by a train to delay itself\n",
    "\tdef _delay(self, a, maps, rail, direction, delay):\n",
    "\t\ttpc = self.tpc[a]\n",
    "\n",
    "\t\told_rail, old_dir = self._get_rail_dir(a, maps)\n",
    "\n",
    "\t\tmaps[a] = np.roll(maps[a], delay)\n",
    "\t\t# Reset the first bits\n",
    "\t\tmaps[a, :, 0:delay+tpc] = 0\n",
    "\t\t# Fill the first with the current rail info\n",
    "\t\tmaps[a, old_rail, 0:tpc] = old_dir\n",
    "\t\t# Add delay to the next rail\n",
    "\t\tmaps[a, rail, tpc:tpc+delay] = direction\n",
    "\t\t\n",
    "\t\treturn maps\n",
    "\n",
    "\tdef _is_cell_occupied(self, a, cell):\n",
    "\t\toccupied = False\n",
    "\n",
    "\t\tfor other in range(self.env.get_num_agents()):\n",
    "\t\t\tif other != a and self.env.agents[other].position == cell:\n",
    "\t\t\t\toccupied = True\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\treturn occupied\n",
    "\n",
    "\tdef _check_headon_crash(self, a, rail, direction, maps):\n",
    "\t\tcrash = False\n",
    "\n",
    "\t\t# Check if rail is already occupied to compute new exit time\n",
    "\t\tlast, last_exit = self._last_train_on_rail(a, rail, maps)\n",
    "\n",
    "\t\tif last_exit > 0:\n",
    "\t\t\t# last_exit-1 instead of 0, because in 0 it may be crossing the last\n",
    "\t\t\t# cell before the switch\n",
    "\t\t\tlast_dir = maps[last, rail, last_exit - 1]\n",
    "\t\t\tcrash = last_dir != direction\n",
    "\n",
    "\t\treturn crash\n",
    "\n",
    "\tdef check_crash(self, a, maps, is_before_switch=False):\n",
    "\t\tcrash = False\n",
    "\t\tagent = self.env.agents[a]\n",
    "\n",
    "\t\tif agent.status == TrainState.READY_TO_DEPART:\n",
    "\t\t\t# init_pos not occupied\n",
    "\t\t\tnext_pos = agent.initial_position\n",
    "\t\t\tcrash = self._is_cell_occupied(a, next_pos)\n",
    "\n",
    "\t\t\tif not crash:\n",
    "\t\t\t\t# We should skip the first bit that is 0\n",
    "\t\t\t\trail, direction = self._get_rail_dir(a, maps, ts=1)\n",
    "\t\t\t\tcrash = self._check_headon_crash(a, rail, direction, maps)\n",
    "\n",
    "\t\telif is_before_switch:\n",
    "\t\t\ttpc = self.tpc[a]\n",
    "\t\t\tnext_rail, next_dir = self._get_rail_dir(a, maps, ts=tpc)\n",
    "\t\t\tcrash = self._check_headon_crash(a, next_rail, next_dir, maps)\n",
    "\n",
    "\t\telse: # action_required\n",
    "\t\t\tif len(self.paths[a]) > 0:\n",
    "\t\t\t\tnext_pos = self.paths[a][0].next_action_element.next_position\n",
    "\t\t\t\tcrash = self._is_cell_occupied(a, next_pos)\n",
    "\n",
    "\t\treturn crash\n",
    "\n",
    "\tdef update_bitmaps(self, a, maps, is_before_switch=False):\n",
    "\t\t# Calculate exit time when switching rail\n",
    "\t\tif is_before_switch:\n",
    "\t\t\ttpc = self.tpc[a]\n",
    "\t\t\tnext_rail, next_dir = self._get_rail_dir(a, maps, ts=tpc)\n",
    "\n",
    "\t\t\t# Check if rail is already occupied to compute new exit time\n",
    "\t\t\t_, last_exit = self._last_train_on_rail(a, next_rail, maps)\n",
    "\t\t\tif last_exit > 0:\n",
    "\t\t\t\t# tpc: skips the first bits that are curr_rail\n",
    "\t\t\t\tcurr_exit = np.argmax(maps[a, next_rail, tpc:] == 0)\n",
    "\t\t\t\t# Also consider the last cell of curr_rail\n",
    "\t\t\t\tcurr_exit += tpc\n",
    "\t\t\t\t# TODO? something changes if the last id is > or <  ?\n",
    "\t\t\t\tif curr_exit <= last_exit:\n",
    "\t\t\t\t\tdelay = last_exit + tpc - curr_exit\n",
    "\t\t\t\t\tmaps = self._delay(a, maps, next_rail, next_dir, delay)\n",
    "\n",
    "\t\tmaps[a, :, 0] = 0\n",
    "\t\tmaps[a] = np.roll(maps[a], -1)\n",
    "\t\treturn maps\n",
    "\t\n",
    "\tdef set_agent_path(self, a, path):\n",
    "\t\tself.paths[a] = path\n",
    "\n",
    "\tdef _last_train_on_rail(self, a, rail, maps):\n",
    "\t\t\"\"\"\n",
    "\t\tFind train preceding agent 'handle' on rail.\n",
    "\t\t:param maps: \n",
    "\t\t:param rail: \n",
    "\t\t:param handle: \n",
    "\t\t:return: \n",
    "\t\t\"\"\"\n",
    "\t\tlast, last_exit = 0, 0 # Final train, its expected exit time\n",
    "\n",
    "\t\tfor other in range(self.env.get_num_agents()):\n",
    "\t\t\tif other == a or self.env.agents[other].status == TrainState.READY_TO_DEPART:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\ttpc = self.tpc[other]\n",
    "\n",
    "\t\t\t# If agent is already on this rail\n",
    "\t\t\tif maps[other, rail, 0] != 0:\n",
    "\t\t\t\t# Add the estimated exit time\n",
    "\t\t\t\tother_exit = np.argmax(maps[other, rail, :] == 0)\n",
    "\n",
    "\t\t\t\tif other_exit > last_exit:\n",
    "\t\t\t\t\tlast, last_exit = other, other_exit\n",
    "\n",
    "\t\t\t# We use tpc-1, to skip the first bits of trains that have decided\n",
    "\t\t\t# to enter rail, but are still crossing the cell before\n",
    "\t\t\t# If an agent has not yet decided in tpc-1 it will be in the old rail \n",
    "\t\t\telif maps[other, rail, tpc - 1] != 0:\n",
    "\t\t\t\tother_rail, _ = self._get_rail_dir(other, maps)\n",
    "\t\t\t\tother_exit = 0\n",
    "\n",
    "\t\t\t\t# Consider the time to cross the current cell\n",
    "\t\t\t\tif other_rail != rail:\n",
    "\t\t\t\t\tother_exit = np.argmax(maps[other, other_rail, :] == 0)\n",
    "\n",
    "\t\t\t\t# TODO! CHECK\n",
    "\t\t\t\t# Add the estimated exit time\n",
    "\t\t\t\tother_exit += np.argmax(maps[other, rail, other_exit:] == 0)\n",
    "\n",
    "\t\t\t\tif other_exit > last_exit:\n",
    "\t\t\t\t\tlast, last_exit = other, other_exit\n",
    "\n",
    "\t\treturn last, last_exit\n",
    "\n",
    "\tdef _get_trains_on_rails(self, maps, rail, handle):\n",
    "\t\ttrains = []\n",
    "\t\tfor a in range(self.env.get_num_agents()):\n",
    "\t\t\tif not (maps[a, rail, 0] == 0 or a == handle):\n",
    "\t\t\t\texpected_exit_time = np.argmax(maps[a, rail, :] == 0) # Takes index/ts of last bit in a row\n",
    "\t\t\t\ttrains.append((a, expected_exit_time))\n",
    "\t\ttrains.sort()\n",
    "\t\t\n",
    "\t\treturn trains\n",
    "\n",
    "\tdef _get_edge_from_cell(self, cell):\n",
    "\t\t\"\"\"\n",
    "\t\t:param cell: Cell for which we want to find the associated rail id.\n",
    "\t\t:return: A tuple (id rail, dist) where dist is the distance as offset from the beginning of the rail.\n",
    "\t\t\"\"\"\n",
    "\t\tfor edge in self.id_edge_to_cells.keys():\n",
    "\t\t\tcells = [cell[0] for cell in self.id_edge_to_cells[edge]] \n",
    "\t\t\tif cell in cells:\n",
    "\t\t\t\treturn edge, cells.index(cell)\n",
    "\n",
    "\t\treturn -1, -1  # Node\n",
    "\n",
    "\tdef _bitmap_from_cells_seq(self, handle, path) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute bitmap for agent handle, given a selected path.\n",
    "\t\t:param handle: \n",
    "\t\t:return: \n",
    "\t\t\"\"\"\n",
    "\t\tbitmap = np.zeros((self.num_rails, self.max_time_steps + 1), dtype=int)  # Max steps in the future + current ts\n",
    "\t\tagent = self.env.agents[handle]\n",
    "\t\t# Truncate path in the future, after reaching target\n",
    "\t\ttarget_index = [i for i, pos in enumerate(path) if pos[0] == agent.target[0] and pos[1] == agent.target[1]]\n",
    "\t\tif len(target_index) != 0:\n",
    "\t\t\ttarget_index = target_index[0]\n",
    "\t\t\tpath = path[:target_index + 1]\n",
    "\n",
    "\t\t# Add 0 at first ts - for 'not departed yet'\n",
    "\t\trail, _ = self._get_edge_from_cell(path[0])\n",
    "\n",
    "\t\t# Agent's cardinal node, where it entered the last edge\n",
    "\t\tagent_entry_node = None\n",
    "\t\t# Calculate initial edge entry point\n",
    "\t\ti = 0\n",
    "\t\trail, _ = self._get_edge_from_cell(path[i])\n",
    "\t\tif rail != -1: # If it's on an edge\n",
    "\t\t\tinitial_rail = rail\n",
    "\t\t\t# Search first switch\n",
    "\t\t\twhile rail != -1:\n",
    "\t\t\t\ti += 1\n",
    "\t\t\t\trail, _ = self._get_edge_from_cell(path[i])\n",
    "\n",
    "\t\t\tsrc, dst, _ = self.info[initial_rail]\n",
    "\t\t\tnode_id = self.cell_to_id_node[path[i]]\n",
    "\t\t\t# Reversed because we want the switch's cp\n",
    "\t\t\tentry_cp = self._reverse_dir(direction_to_point(path[i-1], path[i]))\n",
    "\t\t\t# If we reach the dst node\n",
    "\t\t\tif (node_id, entry_cp) == dst:\n",
    "\t\t\t\t# We entered from the src node (cross_dir = 1)\n",
    "\t\t\t\tagent_entry_node = src\n",
    "\t\t\t# Otherwise the opposite\n",
    "\t\t\telif (node_id, entry_cp) == src: \n",
    "\t\t\t\tagent_entry_node = dst\n",
    "\t\telse:\n",
    "\t\t\t#Handle the case you call this while on a switch before a rail\n",
    "\t\t\tnode_id = self.cell_to_id_node[path[i]]\n",
    "\t\t\t# Calculate exit direction (that's the entry cp for the next edge)\n",
    "\t\t\tcp = direction_to_point(path[0], path[1]) # it's ok\n",
    "\t\t\t# Not reversed because it's already relative to a switch\n",
    "\t\t\tagent_entry_node = CardinalNode(node_id, cp)\n",
    "\n",
    "\t\tholes = 0\n",
    "\t\t# Fill rail occupancy according to predicted position at ts\n",
    "\t\tfor ts in range(0, len(path)):\n",
    "\t\t\tcell = path[ts]\n",
    "\t\t\t# Find rail associated to cell\n",
    "\t\t\trail, _ = self._get_edge_from_cell(cell)\n",
    "\t\t\t# Find crossing direction\n",
    "\t\t\tif rail == -1: # Agent is on a switch\n",
    "\t\t\t\tholes += 1\n",
    "\t\t\t\t# Skip duplicated cells (for agents with fractional speed)\n",
    "\t\t\t\tif ts+1 < len(path) and cell != path[ts+1]:\n",
    "\t\t\t\t\tnode_id = self.cell_to_id_node[cell]\n",
    "\t\t\t\t\t# Calculate exit direction (that's the entry cp for the next edge)\n",
    "\t\t\t\t\tcp = direction_to_point(cell, path[ts+1])\n",
    "\t\t\t\t\t# Not reversed because it's already relative to a switch\n",
    "\t\t\t\t\tagent_entry_node = CardinalNode(node_id, cp)\n",
    "\t\t\telse: # Agent is on a rail\n",
    "\t\t\t\tcrossing_dir = None\n",
    "\t\t\t\tsrc, dst, _ = self.info[rail]\n",
    "\t\t\t\tif agent_entry_node == dst:\n",
    "\t\t\t\t\tcrossing_dir = 1\n",
    "\t\t\t\telif agent_entry_node == src: \n",
    "\t\t\t\t\tcrossing_dir = -1\n",
    "\n",
    "\t\t\t\tassert crossing_dir != None\n",
    "\n",
    "\t\t\t\tbitmap[rail, ts] = crossing_dir\n",
    "\n",
    "\t\t\t\tif holes > 0:\n",
    "\t\t\t\t\tbitmap[rail, ts-holes:ts] = crossing_dir\n",
    "\t\t\t\t\tholes = 0\n",
    "\n",
    "\t\tassert(holes == 0, \"All the cells of the bitmap should be filled\")\n",
    "\n",
    "\t\ttemp = np.any(bitmap[:, 1:(len(path)-1)] != 0, axis=0)\n",
    "\t\tassert(np.all(temp), \"Thee agent's bitmap shouldn't have holes \")\n",
    "\t\treturn bitmap\n",
    "\n",
    "\t# Slightly modified wrt to the other\n",
    "\tdef _map_to_graph(self):\n",
    "\t\t\"\"\"\n",
    "\t\tBuild the representation of the map as a graph.\n",
    "\t\t:return: \n",
    "\t\t\"\"\"\n",
    "\t\tid_node_counter = 0\n",
    "\t\tconnections = {}\n",
    "\t\t# targets = [agent.target for agent in self.env.agents]\n",
    "\n",
    "\t\t# Identify cells hat are nodes (switches or diamond crossings)\n",
    "\t\tfor i in range(self.env.height):\n",
    "\t\t\tfor j in range(self.env.width):\n",
    "\n",
    "\t\t\t\tis_switch = False\n",
    "\t\t\t\tis_crossing = False\n",
    "\t\t\t\t# is_target = False\n",
    "\t\t\t\tconnections_matrix = np.zeros((4, 4))  # Matrix NESW x NESW\n",
    "\n",
    "\t\t\t\t# Check if diamond crossing\n",
    "\t\t\t\ttransitions_bit = bin(self.env.rail.get_full_transitions(i, j))\n",
    "\t\t\t\tif int(transitions_bit, 2) == int('1000010000100001', 2):\n",
    "\t\t\t\t\tis_crossing = True\n",
    "\t\t\t\t\tconnections_matrix[0, 2] = connections_matrix[2, 0] = 1\n",
    "\t\t\t\t\tconnections_matrix[1, 3] = connections_matrix[3, 1] = 1\n",
    "\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t# Check if target\n",
    "\t\t\t\t\t# if (i, j) in targets:\n",
    "\t\t\t\t\t#\tis_target = True\n",
    "\t\t\t\t\t# Check if switch\n",
    "\t\t\t\t\tfor direction in (0, 1, 2, 3):  # 0:N, 1:E, 2:S, 3:W\n",
    "\t\t\t\t\t\tpossible_transitions = self.env.rail.get_transitions(i, j, direction)\n",
    "\t\t\t\t\t\tfor t in range(4):  # Check groups of bits\n",
    "\t\t\t\t\t\t\tif possible_transitions[t]:\n",
    "\t\t\t\t\t\t\t\tinv_direction = (direction + 2) % 4\n",
    "\t\t\t\t\t\t\t\tconnections_matrix[inv_direction, t] = connections_matrix[t, inv_direction] = 1\n",
    "\t\t\t\t\t\tnum_transitions = np.count_nonzero(possible_transitions)\n",
    "\t\t\t\t\t\tif num_transitions > 1:\n",
    "\t\t\t\t\t\t\tis_switch = True\n",
    "\n",
    "\t\t\t\tif is_switch or is_crossing: #or is_target:\n",
    "\t\t\t\t\t# Add node - keep info on cell position\n",
    "\t\t\t\t\t# Update only for nodes that are switches\n",
    "\t\t\t\t\tconnections.update({id_node_counter: connections_matrix})\n",
    "\t\t\t\t\tself.id_node_to_cell.update({id_node_counter: (i, j)})\n",
    "\t\t\t\t\tself.cell_to_id_node.update({(i, j): id_node_counter})\n",
    "\t\t\t\t\tid_node_counter += 1\n",
    "\n",
    "\t\t# Enumerate edges from these nodes\n",
    "\t\tid_edge_counter = 0\n",
    "\t\t# Start from connections of one node and follow path until next switch is found\n",
    "\t\tnodes = connections.keys()  # ids\n",
    "\t\tvisited = set()  # Keeps set of CardinalNodes that were already visited\n",
    "\t\tfor n in nodes:\n",
    "\t\t\tfor cp in range(4):  # Check edges from the 4 cardinal points\n",
    "\t\t\t\tif np.count_nonzero(connections[n][cp, :]) > 0:\n",
    "\t\t\t\t\tvisited.add(CardinalNode(n, cp))  # Add to visited\n",
    "\t\t\t\t\tcells_sequence = []\n",
    "\t\t\t\t\tnode_found = False\n",
    "\t\t\t\t\tedge_length = 0\n",
    "\t\t\t\t\t# Keep going until another node is found\n",
    "\t\t\t\t\tdirection = cp\n",
    "\t\t\t\t\tpos = self.id_node_to_cell[n]\n",
    "\t\t\t\t\twhile not node_found:\n",
    "\t\t\t\t\t\tneighbour_pos = get_new_position(pos, direction)\n",
    "\t\t\t\t\t\tcells_sequence.append((neighbour_pos, direction))\n",
    "\t\t\t\t\t\tif neighbour_pos in self.cell_to_id_node:  # If neighbour is a node\n",
    "\t\t\t\t\t\t\t# node_found = True\n",
    "\t\t\t\t\t\t\t# Build edge, mark visited\n",
    "\t\t\t\t\t\t\tid_node1 = n\n",
    "\t\t\t\t\t\t\tcp1 = cp\n",
    "\t\t\t\t\t\t\tid_node2 = self.cell_to_id_node[neighbour_pos]\n",
    "\t\t\t\t\t\t\tcp2 = self._reverse_dir(direction)\n",
    "\t\t\t\t\t\t\tif CardinalNode(id_node2, cp2) not in visited:\n",
    "\t\t\t\t\t\t\t\tself.info.update({id_edge_counter:\n",
    "\t\t\t\t\t\t\t\t\t                  (CardinalNode(id_node1, cp1),\n",
    "\t\t\t\t\t\t\t\t\t                   CardinalNode(id_node2, cp2),\n",
    "\t\t\t\t\t\t\t\t\t                   edge_length)})\n",
    "\t\t\t\t\t\t\t\tcells_sequence.pop()  # Don't include this node in the edge\n",
    "\t\t\t\t\t\t\t\tself.id_edge_to_cells.update({id_edge_counter: cells_sequence})\n",
    "\t\t\t\t\t\t\t\tid_edge_counter += 1\n",
    "\t\t\t\t\t\t\t\tvisited.add(CardinalNode(id_node2, cp2))\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\tedge_length += 1  # Not considering switches in the count\n",
    "\t\t\t\t\t\t# Update pos and dir\n",
    "\t\t\t\t\t\tpos = neighbour_pos\n",
    "\t\t\t\t\t\texit_dir = self._reverse_dir(direction)\n",
    "\t\t\t\t\t\tpossible_transitions = np.array(self.env.rail.get_transitions(pos[0], pos[1], direction))\n",
    "\t\t\t\t\t\tpossible_transitions[exit_dir] = 0  # Don't consider direction from which I entered\n",
    "\t\t\t\t\t\t# t = 2\n",
    "\t\t\t\t\t\tt = np.argmax(possible_transitions)  # There's only one possible transition except the one that I took to get in\n",
    "\t\t\t\t\t\ttemp_pos = get_new_position(pos, t)\n",
    "\t\t\t\t\t\tif 0 <= temp_pos[0] < self.env.height and 0 <= temp_pos[1] < self.env.width:  # Patch - check if this cell is a rail\n",
    "\t\t\t\t\t\t\t# Entrance dir is always opposite to exit dir\n",
    "\t\t\t\t\t\t\tdirection = t\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tbreak\n",
    "\n",
    "\t\tself.nodes = nodes # Set of nodes\n",
    "\t\tself.edges = self.info.keys() # Set of edges\n",
    "\t\tself.num_rails = len(self.edges)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef _reverse_dir(direction):\n",
    "\t\t\"\"\"\n",
    "\t\tInvert direction (int) of one agent.\n",
    "\t\t:param direction: \n",
    "\t\t:return: \n",
    "\t\t\"\"\"\n",
    "\t\treturn int((direction + 2) % 4)\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortest path prediction builder (Romain's one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "def get_shortest_paths(env, vis=False):\n",
    "    distance_map = DistanceMap(env.agents, env.width, env.height)\n",
    "    distance_map.reset(env.agents, env.rail)\n",
    "    distance_map.get()\n",
    "\n",
    "    # Visualize the distance map\n",
    "    if vis:\n",
    "        sp.visualize_distance_map(distance_map, 0)\n",
    "        sp.visualize_distance_map(distance_map, 1)\n",
    "\n",
    "    shortest_paths = sp.get_shortest_paths(distance_map)\n",
    "    for handle in shortest_paths.keys():\n",
    "        if len(shortest_paths) <= 1:\n",
    "            shortest_paths[handle] = 2\n",
    "        elif env.agents[handle].position is None:\n",
    "            shortest_paths[handle] = 2 # Forward = start moving in the map\n",
    "        else:\n",
    "            next_cell = shortest_paths[handle][1] # Next cell to visit\n",
    "            shortest_paths[handle] = sp.get_action_for_move(env.agents[handle].position, \n",
    "                                                        env.agents[handle].direction,\n",
    "                                                        next_cell.position,\n",
    "                                                        next_cell.direction,\n",
    "                                                        env.rail)\n",
    "    return shortest_paths\n",
    "\n",
    "# Test the shortest path function\n",
    "actions = get_shortest_paths(env, vis=True)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAgentShortest(TreeObsForRailEnv):\n",
    "    '''Implements shortest path observation for the agents.'''\n",
    "    def __init__(self):\n",
    "        super().__init__(max_depth=0)\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "\n",
    "    def get(self, handle):\n",
    "        return get_shortest_paths(self.env)[handle]\n",
    "\n",
    "# Create the environment\n",
    "env = RailEnv(\n",
    "    width=40,\n",
    "    height=35,\n",
    "    rail_generator=SparseRailGen(\n",
    "        seed=0,  # Random seed\n",
    "        max_num_cities=3,  # Number of cities\n",
    "        grid_mode=False,\n",
    "        max_rails_between_cities=1,\n",
    "        max_rail_pairs_in_city=1,\n",
    "    ),\n",
    "    line_generator=SparseLineGen(speed_ratio_map={1.: 1.},\n",
    "        seed=0,  # Random seed\n",
    "        ),\n",
    "    number_of_agents=8,\n",
    "    obs_builder_object=SingleAgentShortest(),\n",
    "    malfunction_generator=ParamMalfunctionGen(\n",
    "        MalfunctionParameters(\n",
    "            malfunction_rate=0.,  # Rate of malfunction\n",
    "            min_duration=3,  # Minimal duration\n",
    "            max_duration=20,  # Max duration\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "obs, info = env.reset()\n",
    "# Print initial position for agent 0\n",
    "a = env.agents[0]\n",
    "print(\"Initial agent position: \", a.initial_position)\n",
    "print(\"Initial agent direction: \", a.initial_direction)\n",
    "print(\"Initial agent target: \", a.target)\n",
    "\n",
    "# Step loop\n",
    "for step in range(10):\n",
    "    actions = {}\n",
    "    for handle in env.get_agent_handles():\n",
    "        actions[handle] = obs[handle]\n",
    "    print(\"Step\", step)\n",
    "    print(\"Actions\", actions)\n",
    "    obs, all_rewards, done, _ = env.step(actions)\n",
    "\n",
    "# Agent's info for agent 0\n",
    "print(a)\n",
    "print(obs[a.handle])\n",
    "\n",
    "# Render the final environment\n",
    "env_renderer = RenderTool(env)\n",
    "image = env_renderer.render_env(return_image=True, show_inactive_agents=True)\n",
    "plt.figure(figsize=(20, 10), dpi=300)\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collection of environment-specific PredictionBuilder.\n",
    "\"\"\"\n",
    "\n",
    "from flatland.core.env_prediction_builder import PredictionBuilder\n",
    "from flatland.envs.agent_utils import RailAgentStatus\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.distance_map import DistanceMap\n",
    "from flatland.envs.rail_env import RailEnvActions, RailEnvNextAction\n",
    "from flatland.envs.rail_env_shortest_paths import get_new_position\n",
    "from flatland.utils.ordered_set import OrderedSet\n",
    "\n",
    "class ShortestPathPredictorForRailEnv(PredictionBuilder):\n",
    "    \"\"\"\n",
    "    ShortestPathPredictorForRailEnv object.\n",
    "\n",
    "    This object returns shortest-path predictions for agents in the RailEnv environment.\n",
    "    The prediction acts as if no other agent is in the environment and always takes the forward action.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_depth: int = 20):\n",
    "        self.shortest_paths = None\n",
    "\n",
    "        self.empty_prediction = np.zeros(shape=(max_depth + 1, 5))\n",
    "        for i in range(max_depth + 1):\n",
    "            self.empty_prediction[i] = [i, None, None, None, None]\n",
    "\n",
    "        super().__init__(max_depth)\n",
    "\n",
    "    def get(self, handle: int = None):\n",
    "        \"\"\"\n",
    "        Requires distance_map to extract the shortest path.\n",
    "        Does not take into account future positions of other agents!\n",
    "\n",
    "        If there is no shortest path, the agent just stands still and stops moving.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        handle : int, optional\n",
    "            Handle of the agent for which to compute the observation vector.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Returns a dictionary indexed by the agent handle and for each agent a vector of (max_depth + 1)x5 elements:\n",
    "            - time_offset\n",
    "            - position x\n",
    "            - position y\n",
    "            - direction\n",
    "            - action taken to come here\n",
    "            The prediction at 0 is the current position, direction etc.\n",
    "        \"\"\"\n",
    "        agents = self.env.agents\n",
    "        if handle:\n",
    "            agents = [self.env.agents[handle]]\n",
    "        distance_map: DistanceMap = self.env.distance_map\n",
    "        # Use map_depth + 1 to consider current time step\n",
    "        self.shortest_paths = shortest_paths = get_shortest_paths(\n",
    "            distance_map, max_depth=self.max_depth + 1)\n",
    "\n",
    "        prediction_dict = {}\n",
    "        for agent in agents:\n",
    "            handle = agent.handle\n",
    "            prediction_dict[handle] = self.prediction_from_path(handle, shortest_paths[handle])\n",
    "\n",
    "        return prediction_dict\n",
    "\n",
    "    def get_altpaths(self, handle, cell_to_id_node):\n",
    "        altpaths = get_altpaths(handle, self.env.distance_map, 500, cell_to_id_node)\n",
    "        cells_seqs = []\n",
    "        predictions = []\n",
    "        for path in altpaths:\n",
    "            prediction = self.prediction_from_path(handle, path)\n",
    "            predictions.append(prediction)\n",
    "            cells_seqs.append(self.cells_seq_from_prediction(handle, prediction))\n",
    "        \n",
    "        return altpaths, cells_seqs\n",
    "\n",
    "    def prediction_from_path(self, handle, path):\n",
    "        agent = self.env.agents[handle]\n",
    "        prediction = np.zeros(shape=(self.max_depth + 1, 5), dtype=int)\n",
    "\n",
    "        if agent.status == RailAgentStatus.READY_TO_DEPART:\n",
    "            agent_virtual_position = agent.initial_position\n",
    "        elif agent.status == RailAgentStatus.ACTIVE:\n",
    "            agent_virtual_position = agent.position\n",
    "        elif agent.status == RailAgentStatus.DONE:\n",
    "            agent_virtual_position = agent.target\n",
    "        else:  # agent.status == DONE_REMOVED, prediction must be None\n",
    "            return self.empty_prediction\n",
    "\n",
    "        agent_virtual_direction = agent.direction\n",
    "        agent_speed = agent.speed_data[\"speed\"]\n",
    "        times_per_cell = int(np.reciprocal(agent_speed))\n",
    "        # First cell is info relative to actual time step\n",
    "        prediction[0] = [0, *agent_virtual_position,\n",
    "                            agent_virtual_direction, RailEnvActions.MOVE_FORWARD] # TODO dell'action\n",
    "\n",
    "        # If there is a shortest path, remove the initial position\n",
    "        if path:\n",
    "            path = path[1:]\n",
    "\n",
    "        new_direction = agent_virtual_direction\n",
    "        new_position = agent_virtual_position\n",
    "        visited = OrderedSet()\n",
    "        for index in range(1, self.max_depth + 1):\n",
    "            action = RailEnvActions.MOVE_FORWARD\n",
    "            # If we're at the target or not moving, stop moving until max_depth is reached\n",
    "            # if new_position == agent.target or not agent.moving or not path:\n",
    "            # Writing like this you don't consider the fact that the agent is stopped\n",
    "            if new_position == agent.target or not path:\n",
    "                prediction[index] = [index, *new_position,\n",
    "                                        new_direction, RailEnvActions.STOP_MOVING]\n",
    "                visited.add((*new_position, agent.direction))\n",
    "                continue\n",
    "\n",
    "            if index % times_per_cell == 0:\n",
    "                new_position = path[0].position\n",
    "                new_direction = path[0].direction\n",
    "\n",
    "                action = path[0][2].action\n",
    "\n",
    "                path = path[1:]\n",
    "\n",
    "            # Prediction is ready\n",
    "            prediction[index] = [index, *new_position, new_direction, action]\n",
    "            visited.add((*new_position, new_direction))\n",
    "\n",
    "        return prediction\n",
    "\n",
    "    def cells_seq_from_prediction(self, handle, prediction):\n",
    "        cells_sequence = []\n",
    "        for step in prediction:\n",
    "            cell_pos = (step[1], step[2])  # Takes (yi, xi)\n",
    "            cells_sequence.append(cell_pos)\n",
    "\n",
    "        return cells_sequence\n",
    "\n",
    "    def compute_cells_sequence(self, prediction_dict):\n",
    "        \"\"\"\n",
    "        Given prediction dict for all agents, return sequence of cells walked in the prediction as a dict\n",
    "        where key is the agent handle and value is the list of tuples (xi, yi) that are crossed.\n",
    "        Mostly used to debug.\n",
    "        :param prediction_dict: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "\n",
    "        cells_sequence = defaultdict(list)\n",
    "        agents = self.env.agents\n",
    "        for a in agents:\n",
    "            handle = a.handle\n",
    "            cells_sequence[handle] = self.cells_seq_from_prediction(handle, prediction_dict[handle])\n",
    "\n",
    "        return cells_sequence\n",
    "\n",
    "    def get_prediction_depth(self):\n",
    "        \"\"\"\n",
    "\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        return self.max_depth\n",
    "\n",
    "    def get_shortest_path_action(self, handle):\n",
    "        \"\"\"\n",
    "        Takes an agent handle and returns next action for that agent following shortest path:\n",
    "        - if agent status == READY_TO_DEPART => agent moves forward;\n",
    "        - if agent status == ACTIVE => pick action according to shortest path;\n",
    "        - if agent status == DONE => agent does nothing.\n",
    "        :param handle: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "\n",
    "        agent = self.env.agents[handle]\n",
    "        \n",
    "        if agent.status == RailAgentStatus.READY_TO_DEPART:\n",
    "            action = RailEnvActions.MOVE_FORWARD\n",
    "\n",
    "        elif agent.status == RailAgentStatus.ACTIVE:\n",
    "            # This can return None when rails are disconnected or there was an error in the DistanceMap\n",
    "            if self.shortest_paths[handle] is None:  # Railway disrupted\n",
    "                action = RailEnvActions.STOP_MOVING\n",
    "            else:\n",
    "                step = self.shortest_paths[handle][0]\n",
    "                action = step[2][0]  # Get next_action_element\n",
    "\n",
    "        else:  # If status == DONE\n",
    "            action = RailEnvActions.DO_NOTHING\n",
    "\n",
    "        return action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
